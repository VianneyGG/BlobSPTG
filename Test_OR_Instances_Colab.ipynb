{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d71e66",
   "metadata": {},
   "source": [
    "# Steiner Tree Problem Solver: Testing OR Instances with Blob Simulation\n",
    "\n",
    "## Overview\n",
    "This notebook tests the Steiner Tree Problem solver using **Physarum polycephalum** (blob) simulation on the OR-Library test instances. The blob simulation mimics the behavior of the slime mold to find optimal Steiner trees in graphs.\n",
    "\n",
    "### What is the Steiner Tree Problem?\n",
    "Given a connected graph with weighted edges and a subset of vertices (terminals), find the minimum-weight tree that connects all terminals. Additional vertices (Steiner nodes) may be included to minimize the total weight.\n",
    "\n",
    "### The Blob Algorithm\n",
    "The algorithm simulates the growth patterns of *Physarum polycephalum*, which naturally optimizes network structures by:\n",
    "- Modeling edges as tubes carrying protoplasmic flux\n",
    "- Using pressure differentials to drive flow\n",
    "- Adapting tube conductivities based on usage\n",
    "- Converging to efficient network topologies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc33f12",
   "metadata": {},
   "source": [
    "## 1. Setup Google Colab Environment\n",
    "\n",
    "### Configure Google Colab\n",
    "First, let's configure the environment and check system information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Enable GPU if available\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU not available\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed\")\n",
    "\n",
    "# Check available memory\n",
    "import psutil\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe5f8c",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Setup\n",
    "\n",
    "### Clone the BlobSPTG Repository\n",
    "We'll clone the repository containing the Steiner Tree solver and test instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9587199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your actual repository URL)\n",
    "# For demonstration, we'll simulate the repository structure\n",
    "\n",
    "# If you have a git repository, use:\n",
    "# !git clone https://github.com/yourusername/BlobSPTG.git\n",
    "# %cd BlobSPTG\n",
    "\n",
    "# For now, we'll create the necessary structure and files\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Clone the BlobSPTG repository from GitHub\n",
    "!git clone https://github.com/VianneyGG/BlobSPTG.git\n",
    "%cd BlobSPTG\n",
    "\n",
    "print(f\"Repository cloned successfully!\")\n",
    "print(f\"Changed to directory: {os.getcwd()}\")\n",
    "print(f\"Repository contents: {os.listdir('.')}\")\n",
    "\n",
    "# Check if tests directory exists\n",
    "if os.path.exists('tests'):\n",
    "    test_files = [f for f in os.listdir('tests') if f.endswith('.txt')]\n",
    "    print(f\"\\nFound {len(test_files)} test files in tests/ directory\")\n",
    "    print(f\"Sample test files: {test_files[:5]}...\") if len(test_files) > 5 else print(f\"All test files: {test_files}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Tests directory not found in repository\")\n",
    "\n",
    "# Create project structure\n",
    "project_dir = \"BlobSPTG\"\n",
    "if not os.path.exists(project_dir):\n",
    "    os.makedirs(project_dir)\n",
    "    os.makedirs(f\"{project_dir}/Fonctions\")\n",
    "    os.makedirs(f\"{project_dir}/tests\")\n",
    "    print(f\"Created project directory: {project_dir}\")\n",
    "\n",
    "%cd {project_dir}\n",
    "print(f\"Changed to directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43284bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify test instances from the cloned repository\n",
    "# The repository should already contain all the OR-Library test instances\n",
    "\n",
    "print(\"Checking available test instances...\")\n",
    "\n",
    "if os.path.exists('tests'):\n",
    "    test_files = sorted([f for f in os.listdir('tests') if f.endswith('.txt')])\n",
    "    print(f\"\\nüìù Found {len(test_files)} test files in the repository:\")\n",
    "    \n",
    "    # Group by instance type\n",
    "    instance_types = {}\n",
    "    for filename in test_files:\n",
    "        if len(filename) > 5:\n",
    "            inst_type = filename[5]  # 'b', 'c', 'd', 'e'\n",
    "            if inst_type not in instance_types:\n",
    "                instance_types[inst_type] = []\n",
    "            instance_types[inst_type].append(filename)\n",
    "    \n",
    "    for inst_type, files in sorted(instance_types.items()):\n",
    "        print(f\"  Type {inst_type.upper()}: {len(files)} instances ({files[0]} to {files[-1]})\")\n",
    "    \n",
    "    # Display first few test files for verification\n",
    "    print(f\"\\nüîç Sample test files:\")\n",
    "    for filename in test_files[:3]:\n",
    "        print(f\"  - {filename}\")\n",
    "        \n",
    "    print(f\"\\n‚úÖ All test instances are ready for testing!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Error: tests directory not found!\")\n",
    "    print(\"The repository might not have been cloned correctly.\")\n",
    "    print(\"Available directories:\", [d for d in os.listdir('.') if os.path.isdir(d)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4527c9c",
   "metadata": {},
   "source": [
    "## 3. Install Required Dependencies\n",
    "\n",
    "### Install Python Packages\n",
    "Let's install all the necessary packages for the blob simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that we have all necessary source files\n",
    "print(\"Checking repository structure...\")\n",
    "\n",
    "required_files = ['MS3_PO_MT.py', 'test_evol_vs_smt.py']\n",
    "required_dirs = ['Fonctions', 'tests']\n",
    "\n",
    "print(\"\\nüìÅ Required files:\")\n",
    "for filename in required_files:\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"  ‚úÖ {filename} - Found\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {filename} - Missing\")\n",
    "\n",
    "print(\"\\nüìÇ Required directories:\")\n",
    "for dirname in required_dirs:\n",
    "    if os.path.exists(dirname):\n",
    "        files_count = len(os.listdir(dirname)) if os.path.isdir(dirname) else 0\n",
    "        print(f\"  ‚úÖ {dirname}/ - Found ({files_count} files)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {dirname}/ - Missing\")\n",
    "\n",
    "# Check Fonctions directory content\n",
    "if os.path.exists('Fonctions'):\n",
    "    fonctions_files = os.listdir('Fonctions')\n",
    "    print(f\"\\nüîß Fonctions module files: {fonctions_files}\")\n",
    "\n",
    "print(\"\\nüöÄ Repository verification complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install numpy pandas matplotlib networkx tqdm psutil scipy\n",
    "\n",
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import heapq\n",
    "from math import *\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "print(\"All dependencies installed successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a418509",
   "metadata": {},
   "source": [
    "## 4. Implement the Blob Algorithm\n",
    "\n",
    "### Core Algorithm Functions\n",
    "Let's implement the essential functions for the blob simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca93a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for parsing Steiner tree instances\n",
    "def parse_stein_file(filepath):\n",
    "    \"\"\"Parse a steinX.txt file and extract graph information.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    n_vertices, n_edges = map(int, lines[0].split())\n",
    "    edge_lines = lines[1:1+n_edges]\n",
    "    edges = []\n",
    "    for line in edge_lines:\n",
    "        u, v, cost = map(int, line.split())\n",
    "        edges.append((u, v, cost))\n",
    "    \n",
    "    n_terminals = int(lines[1+n_edges])\n",
    "    # Read terminals from all remaining lines\n",
    "    terminal_lines = lines[2+n_edges:]\n",
    "    terminals = []\n",
    "    for line in terminal_lines:\n",
    "        terminals.extend(map(int, line.split()))\n",
    "    \n",
    "    return n_vertices, n_edges, edges, terminals\n",
    "\n",
    "def build_graph(n_vertices, edges):\n",
    "    \"\"\"Build adjacency matrix from edge list.\"\"\"\n",
    "    G = np.full((n_vertices, n_vertices), np.inf)\n",
    "    for u, v, cost in edges:\n",
    "        G[u-1, v-1] = cost\n",
    "        G[v-1, u-1] = cost\n",
    "    return G\n",
    "\n",
    "print(\"Helper functions implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Blob Algorithm Implementation\n",
    "def simple_blob_steiner(G, terminals, max_iterations=100, alpha=0.15, mu=1.0, delta=0.1):\n",
    "    \"\"\"\n",
    "    Simplified blob simulation for Steiner Tree Problem.\n",
    "    \n",
    "    Args:\n",
    "        G: Adjacency matrix (numpy array)\n",
    "        terminals: Set of terminal indices\n",
    "        max_iterations: Maximum number of iterations\n",
    "        alpha: Learning rate for conductivity updates\n",
    "        mu: Flux strength parameter\n",
    "        delta: Minimum conductivity threshold\n",
    "    \n",
    "    Returns:\n",
    "        Final adjacency matrix with selected edges\n",
    "    \"\"\"\n",
    "    n = G.shape[0]\n",
    "    terminals = list(terminals)\n",
    "    \n",
    "    # Initialize conductivities\n",
    "    D = np.ones_like(G) * 0.1\n",
    "    D[np.isinf(G)] = 0\n",
    "    \n",
    "    # Initialize pressures\n",
    "    pressures = np.zeros(n)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Set boundary conditions (terminals as sources/sinks)\n",
    "        if len(terminals) >= 2:\n",
    "            pressures[terminals[0]] = 1.0  # Source\n",
    "            pressures[terminals[-1]] = 0.0  # Sink\n",
    "        \n",
    "        # Calculate flows using conductivities\n",
    "        flows = np.zeros_like(G)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if not np.isinf(G[i, j]) and D[i, j] > 0:\n",
    "                    flow = D[i, j] * (pressures[i] - pressures[j]) / G[i, j]\n",
    "                    flows[i, j] = flow\n",
    "                    flows[j, i] = -flow\n",
    "        \n",
    "        # Update pressures (simplified pressure calculation)\n",
    "        new_pressures = pressures.copy()\n",
    "        for i in range(n):\n",
    "            if i not in terminals:  # Only update non-terminal nodes\n",
    "                total_flow = 0\n",
    "                total_conductivity = 0\n",
    "                for j in range(n):\n",
    "                    if not np.isinf(G[i, j]) and D[i, j] > 0:\n",
    "                        total_flow += D[i, j] * pressures[j] / G[i, j]\n",
    "                        total_conductivity += D[i, j] / G[i, j]\n",
    "                \n",
    "                if total_conductivity > 0:\n",
    "                    new_pressures[i] = total_flow / total_conductivity\n",
    "        \n",
    "        pressures = new_pressures\n",
    "        \n",
    "        # Update conductivities based on flow\n",
    "        new_D = D.copy()\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if not np.isinf(G[i, j]):\n",
    "                    flow_magnitude = abs(flows[i, j])\n",
    "                    # Reinforcement: increase conductivity for high-flow edges\n",
    "                    new_D[i, j] = max(delta, D[i, j] * (1 + alpha * flow_magnitude))\n",
    "                    new_D[j, i] = new_D[i, j]\n",
    "        \n",
    "        # Apply decay to unused edges\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if not np.isinf(G[i, j]):\n",
    "                    if abs(flows[i, j]) < 0.01:  # Low flow threshold\n",
    "                        new_D[i, j] *= (1 - mu * delta)\n",
    "                        new_D[j, i] = new_D[i, j]\n",
    "        \n",
    "        D = new_D\n",
    "        \n",
    "        # Check convergence (simplified)\n",
    "        if iteration % 20 == 0:\n",
    "            print(f\"Iteration {iteration}: Active edges = {np.sum(D > delta)}\")\n",
    "    \n",
    "    # Extract final tree (edges with significant conductivity)\n",
    "    result = np.full_like(G, np.inf)\n",
    "    threshold = np.max(D) * 0.1  # Adaptive threshold\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if D[i, j] > threshold and not np.isinf(G[i, j]):\n",
    "                result[i, j] = G[i, j]\n",
    "                result[j, i] = G[i, j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Blob algorithm implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa52aed",
   "metadata": {},
   "source": [
    "## 5. Run Tests on OR Instances\n",
    "\n",
    "### Test the Blob Algorithm\n",
    "Now let's test our blob simulation on the OR-Library instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the actual MS3_PO_MT function from the repository\n",
    "try:\n",
    "    from MS3_PO_MT import MS3_PO_MT\n",
    "    print(\"‚úÖ Successfully imported MS3_PO_MT from repository\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import MS3_PO_MT: {e}\")\n",
    "    print(\"Will use simplified blob algorithm instead\")\n",
    "    MS3_PO_MT = None\n",
    "\n",
    "# Known optimal solutions for comparison (from test_evol_vs_smt.py)\n",
    "SMT_OPTIMAL = {\n",
    "    'b': {1: 82.0, 2: 83.0, 3: 138.0, 4: 59.0, 5: 61.0, 6: 122.0, 7: 111.0, 8: 104.0, \n",
    "          9: 220.0, 10: 86.0, 11: 88.0, 12: 174.0, 13: 165.0, 14: 235.0, 15: 318.0, \n",
    "          16: 127.0, 17: 131.0, 18: 218.0},\n",
    "    'c': {1: 85.0, 2: 144.0, 3: 754.0, 4: 1079.0, 5: 1579.0, 6: 55.0, 7: 102.0, \n",
    "          8: 509.0, 9: 707.0, 10: 1093.0, 11: 32.0, 12: 46.0, 13: 258.0, 14: 323.0, \n",
    "          15: 556.0, 16: 11.0, 17: 18.0, 18: 113.0, 19: 146.0, 20: 267.0},\n",
    "    'd': {1: 106.0, 2: 220.0, 3: 1565.0, 4: 1935.0, 5: 3250.0, 6: 67.0, 7: 103.0, \n",
    "          8: 1072.0, 9: 1448.0, 10: 2110.0, 11: 29.0, 12: 42.0, 13: 500.0, 14: 667.0, \n",
    "          15: 1116.0, 16: 13.0, 17: 23.0, 18: 223.0, 19: 310.0, 20: 537.0},\n",
    "    'e': {1: 111.0, 2: 214.0, 3: 4013.0, 4: 5101.0, 5: 8128.0, 6: 73.0, 7: 145.0, \n",
    "          8: 2640.0, 9: 3604.0, 10: 5600.0, 11: 34.0, 12: 67.0, 13: 1280.0, 14: 1732.0, \n",
    "          15: 2784.0, 16: 15.0, 17: 25.0, 18: 564.0, 19: 758.0, 20: 1342.0}\n",
    "}\n",
    "\n",
    "def run_test_on_instance(filename, use_repository_algorithm=True):\n",
    "    \"\"\"Run blob algorithm on a single test instance.\"\"\"\n",
    "    filepath = f'tests/{filename}'\n",
    "    if not os.path.isfile(filepath):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Parse the instance\n",
    "        n_vertices, n_edges, edges, terminals = parse_stein_file(filepath)\n",
    "        G = build_graph(n_vertices, edges)\n",
    "        \n",
    "        print(f\"\\n--- Testing {filename} ---\")\n",
    "        print(f\"Vertices: {n_vertices}, Edges: {n_edges}, Terminals: {len(terminals)}\")\n",
    "        print(f\"Terminal nodes: {terminals}\")\n",
    "        \n",
    "        # Convert terminals to 0-based indexing\n",
    "        terminal_set = set([t-1 for t in terminals])\n",
    "        \n",
    "        # Run algorithm\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if use_repository_algorithm and MS3_PO_MT is not None:\n",
    "            # Use the actual repository algorithm\n",
    "            try:\n",
    "                result_matrix = MS3_PO_MT(G, terminal_set,\n",
    "                                        M=50,  # Number of iterations\n",
    "                                        K=10,  # Population size\n",
    "                                        alpha=0.15,\n",
    "                                        mu=1,\n",
    "                                        delta=0.1,\n",
    "                                        S=3,\n",
    "                                        √©vol=False,\n",
    "                                        modeRenfo='vieillesse',\n",
    "                                        modeProba='weighted')\n",
    "                algorithm_used = \"Repository MS3_PO_MT\"\n",
    "            except Exception as repo_error:\n",
    "                print(f\"Repository algorithm failed: {repo_error}\")\n",
    "                print(\"Falling back to simplified algorithm...\")\n",
    "                result_matrix = simple_blob_steiner(G, terminal_set, max_iterations=50)\n",
    "                algorithm_used = \"Simplified Blob (fallback)\"\n",
    "        else:\n",
    "            # Use simplified algorithm\n",
    "            result_matrix = simple_blob_steiner(G, terminal_set, max_iterations=50)\n",
    "            algorithm_used = \"Simplified Blob\"\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate solution weight\n",
    "        mask = np.isfinite(result_matrix)\n",
    "        solution_weight = np.sum(result_matrix[mask]) / 2  # Divide by 2 for undirected graph\n",
    "        \n",
    "        # Get optimal solution for comparison\n",
    "        instance_type = filename[5]  # 'b', 'c', 'd', 'e'\n",
    "        instance_num = int(filename[6:-4])  # Extract number\n",
    "        optimal_weight = SMT_OPTIMAL.get(instance_type, {}).get(instance_num, float('inf'))\n",
    "        \n",
    "        # Calculate error percentage\n",
    "        if optimal_weight != float('inf'):\n",
    "            error_pct = max(0, (solution_weight - optimal_weight) / optimal_weight * 100)\n",
    "        else:\n",
    "            error_pct = float('inf')\n",
    "        \n",
    "        runtime = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            'file': filename,\n",
    "            'vertices': n_vertices,\n",
    "            'edges': n_edges,\n",
    "            'terminals': len(terminals),\n",
    "            'blob_weight': solution_weight,\n",
    "            'optimal_weight': optimal_weight,\n",
    "            'error_pct': error_pct,\n",
    "            'runtime': runtime,\n",
    "            'algorithm': algorithm_used\n",
    "        }\n",
    "        \n",
    "        print(f\"Algorithm: {algorithm_used}\")\n",
    "        print(f\"Blob solution: {solution_weight:.2f}\")\n",
    "        print(f\"Optimal: {optimal_weight:.2f}\")\n",
    "        print(f\"Error: {error_pct:.2f}%\")\n",
    "        print(f\"Runtime: {runtime:.3f}s\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"Enhanced test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f606fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests on all available instances from the repository\n",
    "results = []\n",
    "\n",
    "if os.path.exists('tests'):\n",
    "    test_files = sorted([f for f in os.listdir('tests/') if f.endswith('.txt')])\n",
    "    \n",
    "    print(f\"Found {len(test_files)} test files in repository\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RUNNING BLOB TESTS ON OR INSTANCES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test a subset first (you can modify this to test all)\n",
    "    # For demonstration, we'll test first few from each type\n",
    "    test_subset = []\n",
    "    instance_types = ['b', 'c', 'd', 'e']\n",
    "    \n",
    "    for inst_type in instance_types:\n",
    "        type_files = [f for f in test_files if f.startswith(f'stein{inst_type}')]\n",
    "        if type_files:\n",
    "            # Test first 3 instances of each type for demo\n",
    "            test_subset.extend(type_files[:3])\n",
    "    \n",
    "    print(f\"Testing subset of {len(test_subset)} instances for demonstration:\")\n",
    "    print(f\"Selected files: {test_subset}\")\n",
    "    print()\n",
    "    \n",
    "    for filename in test_subset:\n",
    "        result = run_test_on_instance(filename, use_repository_algorithm=True)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TESTS COMPLETED - {len(results)} successful tests\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Error: tests directory not found!\")\n",
    "    print(\"Make sure the repository was cloned correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcb1cd",
   "metadata": {},
   "source": [
    "## 6. Analyze Test Results\n",
    "\n",
    "### Results Summary and Visualization\n",
    "Let's analyze the performance of our blob algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da04314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "if not df_results.empty:\n",
    "    print(\"\\nüìä RESULTS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Display results table\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    display_df = df_results.copy()\n",
    "    for col in ['blob_weight', 'optimal_weight', 'error_pct', 'runtime']:\n",
    "        if col in display_df.columns:\n",
    "            display_df[col] = display_df[col].round(3)\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    finite_errors = df_results[df_results['error_pct'] != float('inf')]['error_pct']\n",
    "    if not finite_errors.empty:\n",
    "        print(f\"\\nüìà PERFORMANCE STATISTICS\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"Average error: {finite_errors.mean():.2f}%\")\n",
    "        print(f\"Median error: {finite_errors.median():.2f}%\")\n",
    "        print(f\"Min error: {finite_errors.min():.2f}%\")\n",
    "        print(f\"Max error: {finite_errors.max():.2f}%\")\n",
    "        print(f\"Std deviation: {finite_errors.std():.2f}%\")\n",
    "    \n",
    "    print(f\"\\nAverage runtime: {df_results['runtime'].mean():.3f}s\")\n",
    "    print(f\"Total instances tested: {len(results)}\")\n",
    "    \n",
    "    # Save results\n",
    "    df_results.to_csv('blob_steiner_results.csv', index=False)\n",
    "    print(\"\\nüíæ Results saved to 'blob_steiner_results.csv'\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No valid results to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "if not df_results.empty and len(df_results) > 0:\n",
    "    # Set up the plotting\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Blob Algorithm Performance on OR Instances', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Error percentage distribution\n",
    "    finite_errors = df_results[df_results['error_pct'] != float('inf')]['error_pct']\n",
    "    if not finite_errors.empty:\n",
    "        axes[0, 0].hist(finite_errors, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('Distribution of Error Percentages')\n",
    "        axes[0, 0].set_xlabel('Error (%)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Solution weight comparison\n",
    "    if 'optimal_weight' in df_results.columns:\n",
    "        valid_data = df_results[df_results['optimal_weight'] != float('inf')]\n",
    "        if not valid_data.empty:\n",
    "            axes[0, 1].scatter(valid_data['optimal_weight'], valid_data['blob_weight'], \n",
    "                              alpha=0.7, color='coral')\n",
    "            # Add perfect line\n",
    "            min_val = min(valid_data['optimal_weight'].min(), valid_data['blob_weight'].min())\n",
    "            max_val = max(valid_data['optimal_weight'].max(), valid_data['blob_weight'].max())\n",
    "            axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect')\n",
    "            axes[0, 1].set_title('Blob vs Optimal Solutions')\n",
    "            axes[0, 1].set_xlabel('Optimal Weight')\n",
    "            axes[0, 1].set_ylabel('Blob Weight')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Runtime vs problem size\n",
    "    axes[1, 0].scatter(df_results['vertices'], df_results['runtime'], \n",
    "                       alpha=0.7, color='lightgreen')\n",
    "    axes[1, 0].set_title('Runtime vs Problem Size')\n",
    "    axes[1, 0].set_xlabel('Number of Vertices')\n",
    "    axes[1, 0].set_ylabel('Runtime (seconds)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Error vs problem complexity\n",
    "    if not finite_errors.empty:\n",
    "        complexity_data = df_results[df_results['error_pct'] != float('inf')]\n",
    "        axes[1, 1].scatter(complexity_data['edges'], complexity_data['error_pct'], \n",
    "                          alpha=0.7, color='plum')\n",
    "        axes[1, 1].set_title('Error vs Graph Complexity')\n",
    "        axes[1, 1].set_xlabel('Number of Edges')\n",
    "        axes[1, 1].set_ylabel('Error (%)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(\"\\nüîç DETAILED ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    if not finite_errors.empty:\n",
    "        good_solutions = len(finite_errors[finite_errors <= 5])  # Within 5% of optimal\n",
    "        acceptable_solutions = len(finite_errors[finite_errors <= 10])  # Within 10% of optimal\n",
    "        \n",
    "        print(f\"Solutions within 5% of optimal: {good_solutions}/{len(finite_errors)} ({good_solutions/len(finite_errors)*100:.1f}%)\")\n",
    "        print(f\"Solutions within 10% of optimal: {acceptable_solutions}/{len(finite_errors)} ({acceptable_solutions/len(finite_errors)*100:.1f}%)\")\n",
    "        \n",
    "        # Best and worst performing instances\n",
    "        best_idx = finite_errors.idxmin()\n",
    "        worst_idx = finite_errors.idxmax()\n",
    "        \n",
    "        print(f\"\\nüèÜ Best performance: {df_results.loc[best_idx, 'file']} (Error: {finite_errors.loc[best_idx]:.2f}%)\")\n",
    "        print(f\"‚ö†Ô∏è  Worst performance: {df_results.loc[worst_idx, 'file']} (Error: {finite_errors.loc[worst_idx]:.2f}%)\")\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ccfa9",
   "metadata": {},
   "source": [
    "## 7. Conclusions and Next Steps\n",
    "\n",
    "### Summary\n",
    "This notebook demonstrated the application of **Physarum polycephalum** (blob) simulation to solve the Steiner Tree Problem on OR-Library test instances. The algorithm mimics the natural optimization behavior of slime molds to find efficient network topologies.\n",
    "\n",
    "### Key Observations:\n",
    "1. **Biological Inspiration**: The blob algorithm leverages natural optimization principles\n",
    "2. **Adaptive Behavior**: Conductivities evolve based on usage patterns\n",
    "3. **Scalability**: Performance varies with problem complexity\n",
    "4. **Approximation Quality**: Results compared against known optimal solutions\n",
    "\n",
    "### Algorithm Characteristics:\n",
    "- **Strengths**: Bio-inspired, adaptive, handles complex topologies\n",
    "- **Limitations**: Convergence time, parameter sensitivity\n",
    "- **Applications**: Network design, routing optimization, infrastructure planning\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Parameter Tuning**: Optimize Œ±, Œº, Œ¥ for different instance types\n",
    "2. **Multi-Phase Approach**: Combine with other heuristics\n",
    "3. **Parallel Processing**: Leverage multiple cores for larger instances\n",
    "4. **Advanced Stopping Criteria**: Better convergence detection\n",
    "\n",
    "---\n",
    "\n",
    "### References:\n",
    "- Physarum polycephalum behavior studies\n",
    "- OR-Library Steiner Tree instances\n",
    "- Bio-inspired optimization algorithms\n",
    "- Network optimization literature\n",
    "\n",
    "**Happy optimizing! ü¶†üåü**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
