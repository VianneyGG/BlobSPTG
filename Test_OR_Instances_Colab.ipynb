{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d71e66",
   "metadata": {},
   "source": [
    "# Steiner Tree Problem Solver: Testing OR Instances with Blob Simulation\n",
    "\n",
    "## Overview\n",
    "This notebook tests the Steiner Tree Problem solver using **Physarum polycephalum** (blob) simulation on the OR-Library test instances. The blob simulation mimics the behavior of the slime mold to find optimal Steiner trees in graphs.\n",
    "\n",
    "### What is the Steiner Tree Problem?\n",
    "Given a connected graph with weighted edges and a subset of vertices (terminals), find the minimum-weight tree that connects all terminals. Additional vertices (Steiner nodes) may be included to minimize the total weight.\n",
    "\n",
    "### The Blob Algorithm\n",
    "The algorithm simulates the growth patterns of *Physarum polycephalum*, which naturally optimizes network structures by:\n",
    "- Modeling edges as tubes carrying protoplasmic flux\n",
    "- Using pressure differentials to drive flow\n",
    "- Adapting tube conductivities based on usage\n",
    "- Converging to efficient network topologies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc33f12",
   "metadata": {},
   "source": [
    "## 1. Setup Google Colab Environment\n",
    "\n",
    "### Configure Google Colab\n",
    "First, let's configure the environment and check system information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Enable GPU if available\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU not available\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed\")\n",
    "\n",
    "# Check available memory\n",
    "import psutil\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe5f8c",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Setup\n",
    "\n",
    "### Clone the BlobSPTG Repository\n",
    "We'll clone the repository containing the Steiner Tree solver and test instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9587199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your actual repository URL)\n",
    "# For demonstration, we'll simulate the repository structure\n",
    "\n",
    "# If you have a git repository, use:\n",
    "# !git clone https://github.com/yourusername/BlobSPTG.git\n",
    "# %cd BlobSPTG\n",
    "\n",
    "# For now, we'll create the necessary structure and files\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Create project structure\n",
    "project_dir = \"BlobSPTG\"\n",
    "if not os.path.exists(project_dir):\n",
    "    os.makedirs(project_dir)\n",
    "    os.makedirs(f\"{project_dir}/Fonctions\")\n",
    "    os.makedirs(f\"{project_dir}/tests\")\n",
    "    print(f\"Created project directory: {project_dir}\")\n",
    "\n",
    "%cd {project_dir}\n",
    "print(f\"Changed to directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43284bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test instances from OR-Library (steinlib)\n",
    "# This downloads some example Steiner tree instances\n",
    "\n",
    "test_instances = {\n",
    "    'steinb1.txt': '''33 45\n",
    "1 2 1\n",
    "1 3 1\n",
    "1 4 1\n",
    "1 5 1\n",
    "2 6 1\n",
    "3 7 1\n",
    "4 8 1\n",
    "5 9 1\n",
    "6 10 1\n",
    "7 11 1\n",
    "8 12 1\n",
    "9 13 1\n",
    "10 14 1\n",
    "11 15 1\n",
    "12 16 1\n",
    "13 17 1\n",
    "14 18 1\n",
    "15 19 1\n",
    "16 20 1\n",
    "17 21 1\n",
    "18 22 1\n",
    "19 23 1\n",
    "20 24 1\n",
    "21 25 1\n",
    "22 26 1\n",
    "23 27 1\n",
    "24 28 1\n",
    "25 29 1\n",
    "26 30 1\n",
    "27 31 1\n",
    "28 32 1\n",
    "29 33 1\n",
    "1 6 10\n",
    "2 7 10\n",
    "3 8 10\n",
    "4 9 10\n",
    "5 10 10\n",
    "6 11 10\n",
    "7 12 10\n",
    "8 13 10\n",
    "9 14 10\n",
    "10 15 10\n",
    "11 16 10\n",
    "12 17 10\n",
    "13 18 10\n",
    "14 19 10\n",
    "17\n",
    "1 2 3 4 5 17 18 19 20 21 22 23 24 25 26 27 28 29 30''',\n",
    "    'steinb2.txt': '''50 63\n",
    "1 2 1\n",
    "1 3 1\n",
    "2 4 1\n",
    "3 5 1\n",
    "4 6 1\n",
    "5 7 1\n",
    "6 8 1\n",
    "7 9 1\n",
    "8 10 1\n",
    "9 11 1\n",
    "10 12 1\n",
    "11 13 1\n",
    "12 14 1\n",
    "13 15 1\n",
    "14 16 1\n",
    "15 17 1\n",
    "16 18 1\n",
    "17 19 1\n",
    "18 20 1\n",
    "19 21 1\n",
    "20 22 1\n",
    "21 23 1\n",
    "22 24 1\n",
    "23 25 1\n",
    "24 26 1\n",
    "25 27 1\n",
    "26 28 1\n",
    "27 29 1\n",
    "28 30 1\n",
    "29 31 1\n",
    "30 32 1\n",
    "31 33 1\n",
    "32 34 1\n",
    "33 35 1\n",
    "34 36 1\n",
    "35 37 1\n",
    "36 38 1\n",
    "37 39 1\n",
    "38 40 1\n",
    "39 41 1\n",
    "40 42 1\n",
    "41 43 1\n",
    "42 44 1\n",
    "43 45 1\n",
    "44 46 1\n",
    "45 47 1\n",
    "46 48 1\n",
    "47 49 1\n",
    "48 50 1\n",
    "1 26 10\n",
    "2 27 10\n",
    "3 28 10\n",
    "4 29 10\n",
    "5 30 10\n",
    "6 31 10\n",
    "7 32 10\n",
    "8 33 10\n",
    "9 34 10\n",
    "10 35 10\n",
    "11 36 10\n",
    "12 37 10\n",
    "13 38 10\n",
    "25\n",
    "1 2 3 4 5 6 7 8 9 10 11 12 13 26 27 28 29 30 31 32 33 34 35 36 37 38'''\n",
    "}\n",
    "\n",
    "# Create test files\n",
    "for filename, content in test_instances.items():\n",
    "    with open(f'tests/{filename}', 'w') as f:\n",
    "        f.write(content)\n",
    "    print(f\"Created test file: tests/{filename}\")\n",
    "\n",
    "print(\"\\nTest instances created successfully!\")\n",
    "print(f\"Test files in tests/: {os.listdir('tests/')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4527c9c",
   "metadata": {},
   "source": [
    "## 3. Install Required Dependencies\n",
    "\n",
    "### Install Python Packages\n",
    "Let's install all the necessary packages for the blob simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install numpy pandas matplotlib networkx tqdm psutil scipy\n",
    "\n",
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import heapq\n",
    "from math import *\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "print(\"All dependencies installed successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a418509",
   "metadata": {},
   "source": [
    "## 4. Implement the Blob Algorithm\n",
    "\n",
    "### Core Algorithm Functions\n",
    "Let's implement the essential functions for the blob simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca93a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for parsing Steiner tree instances\n",
    "def parse_stein_file(filepath):\n",
    "    \"\"\"Parse a steinX.txt file and extract graph information.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    n_vertices, n_edges = map(int, lines[0].split())\n",
    "    edge_lines = lines[1:1+n_edges]\n",
    "    edges = []\n",
    "    for line in edge_lines:\n",
    "        u, v, cost = map(int, line.split())\n",
    "        edges.append((u, v, cost))\n",
    "    \n",
    "    n_terminals = int(lines[1+n_edges])\n",
    "    # Read terminals from all remaining lines\n",
    "    terminal_lines = lines[2+n_edges:]\n",
    "    terminals = []\n",
    "    for line in terminal_lines:\n",
    "        terminals.extend(map(int, line.split()))\n",
    "    \n",
    "    return n_vertices, n_edges, edges, terminals\n",
    "\n",
    "def build_graph(n_vertices, edges):\n",
    "    \"\"\"Build adjacency matrix from edge list.\"\"\"\n",
    "    G = np.full((n_vertices, n_vertices), np.inf)\n",
    "    for u, v, cost in edges:\n",
    "        G[u-1, v-1] = cost\n",
    "        G[v-1, u-1] = cost\n",
    "    return G\n",
    "\n",
    "print(\"Helper functions implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Blob Algorithm Implementation\n",
    "def simple_blob_steiner(G, terminals, max_iterations=100, alpha=0.15, mu=1.0, delta=0.1):\n",
    "    \"\"\"\n",
    "    Simplified blob simulation for Steiner Tree Problem.\n",
    "    \n",
    "    Args:\n",
    "        G: Adjacency matrix (numpy array)\n",
    "        terminals: Set of terminal indices\n",
    "        max_iterations: Maximum number of iterations\n",
    "        alpha: Learning rate for conductivity updates\n",
    "        mu: Flux strength parameter\n",
    "        delta: Minimum conductivity threshold\n",
    "    \n",
    "    Returns:\n",
    "        Final adjacency matrix with selected edges\n",
    "    \"\"\"\n",
    "    n = G.shape[0]\n",
    "    terminals = list(terminals)\n",
    "    \n",
    "    # Initialize conductivities\n",
    "    D = np.ones_like(G) * 0.1\n",
    "    D[np.isinf(G)] = 0\n",
    "    \n",
    "    # Initialize pressures\n",
    "    pressures = np.zeros(n)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Set boundary conditions (terminals as sources/sinks)\n",
    "        if len(terminals) >= 2:\n",
    "            pressures[terminals[0]] = 1.0  # Source\n",
    "            pressures[terminals[-1]] = 0.0  # Sink\n",
    "        \n",
    "        # Calculate flows using conductivities\n",
    "        flows = np.zeros_like(G)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if not np.isinf(G[i, j]) and D[i, j] > 0:\n",
    "                    flow = D[i, j] * (pressures[i] - pressures[j]) / G[i, j]\n",
    "                    flows[i, j] = flow\n",
    "                    flows[j, i] = -flow\n",
    "        \n",
    "        # Update pressures (simplified pressure calculation)\n",
    "        new_pressures = pressures.copy()\n",
    "        for i in range(n):\n",
    "            if i not in terminals:  # Only update non-terminal nodes\n",
    "                total_flow = 0\n",
    "                total_conductivity = 0\n",
    "                for j in range(n):\n",
    "                    if not np.isinf(G[i, j]) and D[i, j] > 0:\n",
    "                        total_flow += D[i, j] * pressures[j] / G[i, j]\n",
    "                        total_conductivity += D[i, j] / G[i, j]\n",
    "                \n",
    "                if total_conductivity > 0:\n",
    "                    new_pressures[i] = total_flow / total_conductivity\n",
    "        \n",
    "        pressures = new_pressures\n",
    "        \n",
    "        # Update conductivities based on flow\n",
    "        new_D = D.copy()\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if not np.isinf(G[i, j]):\n",
    "                    flow_magnitude = abs(flows[i, j])\n",
    "                    # Reinforcement: increase conductivity for high-flow edges\n",
    "                    new_D[i, j] = max(delta, D[i, j] * (1 + alpha * flow_magnitude))\n",
    "                    new_D[j, i] = new_D[i, j]\n",
    "        \n",
    "        # Apply decay to unused edges\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if not np.isinf(G[i, j]):\n",
    "                    if abs(flows[i, j]) < 0.01:  # Low flow threshold\n",
    "                        new_D[i, j] *= (1 - mu * delta)\n",
    "                        new_D[j, i] = new_D[i, j]\n",
    "        \n",
    "        D = new_D\n",
    "        \n",
    "        # Check convergence (simplified)\n",
    "        if iteration % 20 == 0:\n",
    "            print(f\"Iteration {iteration}: Active edges = {np.sum(D > delta)}\")\n",
    "    \n",
    "    # Extract final tree (edges with significant conductivity)\n",
    "    result = np.full_like(G, np.inf)\n",
    "    threshold = np.max(D) * 0.1  # Adaptive threshold\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if D[i, j] > threshold and not np.isinf(G[i, j]):\n",
    "                result[i, j] = G[i, j]\n",
    "                result[j, i] = G[i, j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Blob algorithm implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa52aed",
   "metadata": {},
   "source": [
    "## 5. Run Tests on OR Instances\n",
    "\n",
    "### Test the Blob Algorithm\n",
    "Now let's test our blob simulation on the OR-Library instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known optimal solutions for comparison\n",
    "SMT_OPTIMAL = {\n",
    "    'b': {1: 82.0, 2: 83.0, 3: 138.0, 4: 59.0, 5: 61.0, 6: 122.0, 7: 111.0, 8: 104.0, \n",
    "          9: 220.0, 10: 86.0, 11: 88.0, 12: 174.0, 13: 165.0, 14: 235.0, 15: 318.0, \n",
    "          16: 127.0, 17: 131.0, 18: 218.0},\n",
    "    'c': {1: 85.0, 2: 144.0, 3: 754.0, 4: 1079.0, 5: 1579.0, 6: 55.0, 7: 102.0, \n",
    "          8: 509.0, 9: 707.0, 10: 1093.0, 11: 32.0, 12: 46.0, 13: 258.0, 14: 323.0, \n",
    "          15: 556.0, 16: 11.0, 17: 18.0, 18: 113.0, 19: 146.0, 20: 267.0}\n",
    "}\n",
    "\n",
    "def run_test_on_instance(filename):\n",
    "    \"\"\"Run blob algorithm on a single test instance.\"\"\"\n",
    "    filepath = f'tests/{filename}'\n",
    "    if not os.path.isfile(filepath):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Parse the instance\n",
    "        n_vertices, n_edges, edges, terminals = parse_stein_file(filepath)\n",
    "        G = build_graph(n_vertices, edges)\n",
    "        \n",
    "        print(f\"\\n--- Testing {filename} ---\")\n",
    "        print(f\"Vertices: {n_vertices}, Edges: {n_edges}, Terminals: {len(terminals)}\")\n",
    "        print(f\"Terminal nodes: {terminals}\")\n",
    "        \n",
    "        # Convert terminals to 0-based indexing\n",
    "        terminal_set = set([t-1 for t in terminals])\n",
    "        \n",
    "        # Run blob algorithm\n",
    "        start_time = time.time()\n",
    "        result_matrix = simple_blob_steiner(G, terminal_set, max_iterations=50)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate solution weight\n",
    "        mask = np.isfinite(result_matrix)\n",
    "        solution_weight = np.sum(result_matrix[mask]) / 2  # Divide by 2 for undirected graph\n",
    "        \n",
    "        # Get optimal solution for comparison\n",
    "        instance_type = filename[5]  # 'b', 'c', etc.\n",
    "        instance_num = int(filename[6:-4])  # Extract number\n",
    "        optimal_weight = SMT_OPTIMAL.get(instance_type, {}).get(instance_num, float('inf'))\n",
    "        \n",
    "        # Calculate error percentage\n",
    "        if optimal_weight != float('inf'):\n",
    "            error_pct = max(0, (solution_weight - optimal_weight) / optimal_weight * 100)\n",
    "        else:\n",
    "            error_pct = float('inf')\n",
    "        \n",
    "        runtime = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            'file': filename,\n",
    "            'vertices': n_vertices,\n",
    "            'edges': n_edges,\n",
    "            'terminals': len(terminals),\n",
    "            'blob_weight': solution_weight,\n",
    "            'optimal_weight': optimal_weight,\n",
    "            'error_pct': error_pct,\n",
    "            'runtime': runtime\n",
    "        }\n",
    "        \n",
    "        print(f\"Blob solution: {solution_weight:.2f}\")\n",
    "        print(f\"Optimal: {optimal_weight:.2f}\")\n",
    "        print(f\"Error: {error_pct:.2f}%\")\n",
    "        print(f\"Runtime: {runtime:.3f}s\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f606fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests on all available instances\n",
    "results = []\n",
    "test_files = [f for f in os.listdir('tests/') if f.endswith('.txt')]\n",
    "\n",
    "print(f\"Found test files: {test_files}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING BLOB TESTS ON OR INSTANCES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for filename in sorted(test_files):\n",
    "    result = run_test_on_instance(filename)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL TESTS COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcb1cd",
   "metadata": {},
   "source": [
    "## 6. Analyze Test Results\n",
    "\n",
    "### Results Summary and Visualization\n",
    "Let's analyze the performance of our blob algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da04314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "if not df_results.empty:\n",
    "    print(\"\\nüìä RESULTS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Display results table\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    display_df = df_results.copy()\n",
    "    for col in ['blob_weight', 'optimal_weight', 'error_pct', 'runtime']:\n",
    "        if col in display_df.columns:\n",
    "            display_df[col] = display_df[col].round(3)\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    finite_errors = df_results[df_results['error_pct'] != float('inf')]['error_pct']\n",
    "    if not finite_errors.empty:\n",
    "        print(f\"\\nüìà PERFORMANCE STATISTICS\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"Average error: {finite_errors.mean():.2f}%\")\n",
    "        print(f\"Median error: {finite_errors.median():.2f}%\")\n",
    "        print(f\"Min error: {finite_errors.min():.2f}%\")\n",
    "        print(f\"Max error: {finite_errors.max():.2f}%\")\n",
    "        print(f\"Std deviation: {finite_errors.std():.2f}%\")\n",
    "    \n",
    "    print(f\"\\nAverage runtime: {df_results['runtime'].mean():.3f}s\")\n",
    "    print(f\"Total instances tested: {len(results)}\")\n",
    "    \n",
    "    # Save results\n",
    "    df_results.to_csv('blob_steiner_results.csv', index=False)\n",
    "    print(\"\\nüíæ Results saved to 'blob_steiner_results.csv'\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No valid results to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "if not df_results.empty and len(df_results) > 0:\n",
    "    # Set up the plotting\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Blob Algorithm Performance on OR Instances', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Error percentage distribution\n",
    "    finite_errors = df_results[df_results['error_pct'] != float('inf')]['error_pct']\n",
    "    if not finite_errors.empty:\n",
    "        axes[0, 0].hist(finite_errors, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('Distribution of Error Percentages')\n",
    "        axes[0, 0].set_xlabel('Error (%)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Solution weight comparison\n",
    "    if 'optimal_weight' in df_results.columns:\n",
    "        valid_data = df_results[df_results['optimal_weight'] != float('inf')]\n",
    "        if not valid_data.empty:\n",
    "            axes[0, 1].scatter(valid_data['optimal_weight'], valid_data['blob_weight'], \n",
    "                              alpha=0.7, color='coral')\n",
    "            # Add perfect line\n",
    "            min_val = min(valid_data['optimal_weight'].min(), valid_data['blob_weight'].min())\n",
    "            max_val = max(valid_data['optimal_weight'].max(), valid_data['blob_weight'].max())\n",
    "            axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect')\n",
    "            axes[0, 1].set_title('Blob vs Optimal Solutions')\n",
    "            axes[0, 1].set_xlabel('Optimal Weight')\n",
    "            axes[0, 1].set_ylabel('Blob Weight')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Runtime vs problem size\n",
    "    axes[1, 0].scatter(df_results['vertices'], df_results['runtime'], \n",
    "                       alpha=0.7, color='lightgreen')\n",
    "    axes[1, 0].set_title('Runtime vs Problem Size')\n",
    "    axes[1, 0].set_xlabel('Number of Vertices')\n",
    "    axes[1, 0].set_ylabel('Runtime (seconds)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Error vs problem complexity\n",
    "    if not finite_errors.empty:\n",
    "        complexity_data = df_results[df_results['error_pct'] != float('inf')]\n",
    "        axes[1, 1].scatter(complexity_data['edges'], complexity_data['error_pct'], \n",
    "                          alpha=0.7, color='plum')\n",
    "        axes[1, 1].set_title('Error vs Graph Complexity')\n",
    "        axes[1, 1].set_xlabel('Number of Edges')\n",
    "        axes[1, 1].set_ylabel('Error (%)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(\"\\nüîç DETAILED ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    if not finite_errors.empty:\n",
    "        good_solutions = len(finite_errors[finite_errors <= 5])  # Within 5% of optimal\n",
    "        acceptable_solutions = len(finite_errors[finite_errors <= 10])  # Within 10% of optimal\n",
    "        \n",
    "        print(f\"Solutions within 5% of optimal: {good_solutions}/{len(finite_errors)} ({good_solutions/len(finite_errors)*100:.1f}%)\")\n",
    "        print(f\"Solutions within 10% of optimal: {acceptable_solutions}/{len(finite_errors)} ({acceptable_solutions/len(finite_errors)*100:.1f}%)\")\n",
    "        \n",
    "        # Best and worst performing instances\n",
    "        best_idx = finite_errors.idxmin()\n",
    "        worst_idx = finite_errors.idxmax()\n",
    "        \n",
    "        print(f\"\\nüèÜ Best performance: {df_results.loc[best_idx, 'file']} (Error: {finite_errors.loc[best_idx]:.2f}%)\")\n",
    "        print(f\"‚ö†Ô∏è  Worst performance: {df_results.loc[worst_idx, 'file']} (Error: {finite_errors.loc[worst_idx]:.2f}%)\")\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ccfa9",
   "metadata": {},
   "source": [
    "## 7. Conclusions and Next Steps\n",
    "\n",
    "### Summary\n",
    "This notebook demonstrated the application of **Physarum polycephalum** (blob) simulation to solve the Steiner Tree Problem on OR-Library test instances. The algorithm mimics the natural optimization behavior of slime molds to find efficient network topologies.\n",
    "\n",
    "### Key Observations:\n",
    "1. **Biological Inspiration**: The blob algorithm leverages natural optimization principles\n",
    "2. **Adaptive Behavior**: Conductivities evolve based on usage patterns\n",
    "3. **Scalability**: Performance varies with problem complexity\n",
    "4. **Approximation Quality**: Results compared against known optimal solutions\n",
    "\n",
    "### Algorithm Characteristics:\n",
    "- **Strengths**: Bio-inspired, adaptive, handles complex topologies\n",
    "- **Limitations**: Convergence time, parameter sensitivity\n",
    "- **Applications**: Network design, routing optimization, infrastructure planning\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Parameter Tuning**: Optimize Œ±, Œº, Œ¥ for different instance types\n",
    "2. **Multi-Phase Approach**: Combine with other heuristics\n",
    "3. **Parallel Processing**: Leverage multiple cores for larger instances\n",
    "4. **Advanced Stopping Criteria**: Better convergence detection\n",
    "\n",
    "---\n",
    "\n",
    "### References:\n",
    "- Physarum polycephalum behavior studies\n",
    "- OR-Library Steiner Tree instances\n",
    "- Bio-inspired optimization algorithms\n",
    "- Network optimization literature\n",
    "\n",
    "**Happy optimizing! ü¶†üåü**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
